{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# Input Filenames (from notebooks 04 and 05)\n",
    "race_details_input = \"full_race_details_with_mapped_tokens.pickle\"\n",
    "weather_categorical_input = \"weather_conditions_grammar_bins.pickle\"\n",
    "weather_numerical_input = \"numerical_weather_conditions_grammar_and_inverted_indices.pickle\"\n",
    "\n",
    "# Finisher Data Glob\n",
    "race_finisher_pickle_files = glob.glob(\"race_finishers_for_year_*.pickle\")\n",
    "\n",
    "# Output Filename\n",
    "unified_grammar_output = \"race_specific_simplified_grammar\"\n",
    "\n",
    "@dataclass\n",
    "class RaceData:\n",
    "    race_id: str\n",
    "    distance_token: str\n",
    "    vc_conditions_token: str\n",
    "    vc_humidity_token: str\n",
    "    vc_temperature_token: str\n",
    "    vc_feels_like_token: str\n",
    "    vc_wind_speed_token: str\n",
    "    start_date_time: datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_pickle(my_dict, filename_prefix):\n",
    "    filename = f\"{filename_prefix}.pickle\"\n",
    "    if os.path.dirname(filename): os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "    with open(filename, \"wb\") as f: pickle.dump(my_dict, f)\n",
    "    print(f\"Saved to: {filename}\")\n",
    "    return filename\n",
    "\n",
    "def ppj(data):\n",
    "    import json\n",
    "    if isinstance(data, str): data = json.loads(data)\n",
    "    print(json.dumps(data, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading grammar components...\")\n",
    "with open(race_details_input, \"rb\") as f: full_race_details = pickle.load(f)\n",
    "with open(weather_categorical_input, \"rb\") as f: weather_conditions = pickle.load(f)\n",
    "with open(weather_numerical_input, \"rb\") as f: numerical_weather_conditions = pickle.load(f)\n",
    "print(f\"Loaded {len(full_race_details)} years of race data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_datetime(dt_string):\n",
    "    if isinstance(dt_string, datetime): return dt_string\n",
    "    return datetime.strptime(dt_string, \"%Y-%m-%dT%H:%M:%S\")\n",
    "\n",
    "race_specific_simplified_grammar = {}\n",
    "for year in full_race_details:\n",
    "    for race_id in full_race_details[year]:\n",
    "        try:\n",
    "            rd = full_race_details[year][race_id]\n",
    "            w = rd[\"visual_crossing_weather\"]\n",
    "            \n",
    "            race_obj = RaceData(\n",
    "                race_id=race_id,\n",
    "                distance_token=rd[\"distanceNameMappedToken\"],\n",
    "                vc_conditions_token=weather_conditions[w[\"conditions\"]],\n",
    "                vc_humidity_token=numerical_weather_conditions[\"humidity PCT\"][\"inverted_index\"][int(round(w[\"humidity PCT\"]))],\n",
    "                vc_temperature_token=numerical_weather_conditions[\"temperature F\"][\"inverted_index\"][int(round(w[\"temperature F\"]))],\n",
    "                vc_feels_like_token=numerical_weather_conditions[\"feels like F\"][\"inverted_index\"][int(round(w[\"feels like F\"]))],\n",
    "                vc_wind_speed_token=numerical_weather_conditions[\"wind speed mph\"][\"inverted_index\"][int(round(w[\"wind speed mph\"]))],\n",
    "                start_date_time=parse_datetime(rd[\"startDateTime\"])\n",
    "            )\n",
    "            race_specific_simplified_grammar[race_id] = race_obj\n",
    "        except Exception as e: continue\n",
    "\n",
    "print(f\"Processed {len(race_specific_simplified_grammar)} races.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_pickle(race_specific_simplified_grammar, unified_grammar_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load finisher data for verification\n",
    "race_finishers = {}\n",
    "if race_finisher_pickle_files:\n",
    "    print(f\"Found {len(race_finisher_pickle_files)} finisher files.\")\n",
    "    for file_path in sorted(race_finisher_pickle_files):\n",
    "        year = os.path.basename(file_path).replace(\"race_finishers_for_year_\", \"\").replace(\".pickle\", \"\")\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            race_finishers[year] = pickle.load(f)\n",
    "        print(f\"Loaded {year}: {len(race_finishers[year])} races\")\n",
    "    \n",
    "    # Show sample from the first year\n",
    "    if race_finishers:\n",
    "        first_year = sorted(race_finishers.keys())[0]\n",
    "        if race_finishers[first_year]:\n",
    "            sample_race_id = list(race_finishers[first_year].keys())[0]\n",
    "            print(f\"\\nSample finisher data for {sample_race_id} ({first_year}):\")\n",
    "            ppj(race_finishers[first_year][sample_race_id][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
